{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WarmUp Question-4\n",
    "\n",
    "The number of comments posted per year will likely trend upward over time as more users join Reddit. However, the popularity of some subreddits may increase or decrease over time. Find An example of both.\n",
    "\n",
    "As you can see in the \"Reddit Comments Per Year\" chart, the number of comments posted in reddit increasing every year drastically. (Note:2017 numbers are less than expected because we don't have the whole data for 2017.)  <br/>\n",
    "\n",
    "In the second part, we decided to analyze Relationship topic as a subreddit. Even relationships are hot topic for every age and every era interestingly relationship subreddit comments decreased and increased over time. In 2015, the number of relationships subreddit comments decreased enormously to only 2620 comments. <br/>\n",
    "\n",
    "You can check the Implementation Part for our implementation details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Comments Per Year\n",
    "\n",
    "\n",
    "![alt text](https://i.imgur.com/HQvbaQg.jpg \"Logo Title Text 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationships Comments Per Year\n",
    "\n",
    "\n",
    "\n",
    "![alt text](https://i.imgur.com/3LkKQyz.jpg \"Logo Title Text 1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/*/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"AllComments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2006/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2006\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2007/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2007\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2008/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2008\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2009/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2009\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2010/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2010\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2011/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2012/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2012\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2013/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2014/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2015/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2015\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2016/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "originDF = sqlContext.read.json(\"hdfs://orion11:31001/reddit/2017/*\")\n",
    "df = originDF.sample(False, .1)\n",
    "df.createGlobalTempView(\"Comments2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2006 Comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1136102400.0\n",
      "endTime: 1167638399.0\n",
      "SELECT count(*) as 2006_Comments_Count from global_temp.Comments2006 where (created_utc>=1136102400.0 and created_utc<=1167638399.0 )\n",
      "+-------------------+\n",
      "|2006_Comments_Count|\n",
      "+-------------------+\n",
      "|              41771|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as 2006_Comments_Count from global_temp.Comments2006 where subreddit='turkey' and (created_utc>=1136102400.0 and created_utc<=1167638399.0 )\n",
      "+-------------------+\n",
      "|2006_Comments_Count|\n",
      "+-------------------+\n",
      "|                  0|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> dt = datetime.datetime.strptime('2006-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2006-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "sqlString=\"SELECT count(*) as 2006_Comments_Count from global_temp.Comments2006 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2006 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2007 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1167638400.0\n",
      "endTime: 1199174399.0\n",
      "SELECT count(*) as 2007_Comments_Count from global_temp.Comments2007 where (created_utc>=1167638400.0 and created_utc<=1199174399.0 )\n",
      "+-------------------+\n",
      "|2007_Comments_Count|\n",
      "+-------------------+\n",
      "|             246662|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as 2007_Comments_Count from global_temp.Comments2007 where subreddit='relationships' and (created_utc>=1167638400.0 and created_utc<=1199174399.0 )\n",
      "+-------------------+\n",
      "|2007_Comments_Count|\n",
      "+-------------------+\n",
      "|                  0|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> dt = datetime.datetime.strptime('2007-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2007-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "sqlString=\"SELECT count(*) as 2007_Comments_Count from global_temp.Comments2007 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "\n",
    "sqlString=\"SELECT count(*) as 2007_Comments_Count from global_temp.Comments2007 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2008 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1199174400.0\n",
      "endTime: 1230796799.0\n",
      "SELECT count(*) as 2008_Comments_Count from global_temp.Comments2008 where (created_utc>=1199174400.0 and created_utc<=1230796799.0 )\n",
      "+-------------------+\n",
      "|2008_Comments_Count|\n",
      "+-------------------+\n",
      "|             724391|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2008 where subreddit='relationships' and (created_utc>=1199174400.0 and created_utc<=1230796799.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|            0|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> dt = datetime.datetime.strptime('2008-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2008-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "sqlString=\"SELECT count(*) as 2008_Comments_Count from global_temp.Comments2008 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2008 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2009 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1230796800.0\n",
      "endTime: 1262332799.0\n",
      "SELECT count(*) as 2009_Comments_Count from global_temp.Comments2009 where (created_utc>=1230796800.0 and created_utc<=1262332799.0 )\n",
      "+-------------------+\n",
      "|2009_Comments_Count|\n",
      "+-------------------+\n",
      "|            1886520|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2009 where subreddit='relationships' and (created_utc>=1230796800.0 and created_utc<=1262332799.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|            3|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> dt = datetime.datetime.strptime('2009-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2009-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "sqlString=\"SELECT count(*) as 2009_Comments_Count from global_temp.Comments2009 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2009 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2010 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1262332800.0\n",
      "EndTime: 1293868799.0\n",
      "SELECT count(*) as 2010_Comments_Count from global_temp.Comments2010 where (created_utc>=1262332800.0 and created_utc<=1293868799.0 )\n",
      "+-------------------+\n",
      "|2010_Comments_Count|\n",
      "+-------------------+\n",
      "|            4848344|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2010 where subreddit='relationships' and (created_utc>=1262332800.0 and created_utc<=1293868799.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|         6738|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> dt = datetime.datetime.strptime('2010-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2010-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"EndTime:\",endTime)\n",
    "sqlString=\"SELECT count(*) as 2010_Comments_Count from global_temp.Comments2010 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2010 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2011 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1293868800.0\n",
      "EndTime: 1325404799.0\n",
      "SELECT count(*) as 2011_Comments_Count from global_temp.Comments2011 where (created_utc>=1293868800.0 and created_utc<=1325404799.0 )\n",
      "+-------------------+\n",
      "|2011_Comments_Count|\n",
      "+-------------------+\n",
      "|           12322270|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2011 where subreddit='relationships' and (created_utc>=1293868800.0 and created_utc<=1325404799.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|        26324|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> dt = datetime.datetime.strptime('2011-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2011-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"EndTime:\",endTime)\n",
    "sqlString=\"SELECT count(*) as 2011_Comments_Count from global_temp.Comments2011 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2011 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2012 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1325404800.0\n",
      "endTime: 1357027199.0\n",
      "SELECT count(*) as 2012_Comments_Count from global_temp.Comments2012 where (created_utc>=1325404800.0 and created_utc<=1357027199.0 )\n",
      "+-------------------+\n",
      "|2012_Comments_Count|\n",
      "+-------------------+\n",
      "|           26010881|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2012 where subreddit='relationships' and (created_utc>=1325404800.0 and created_utc<=1357027199.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|        65414|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> import time\n",
    ">>> import datetime\n",
    ">>> dt = datetime.datetime.strptime('2012-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2012-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "\n",
    "sqlString=\"SELECT count(*) as 2012_Comments_Count from global_temp.Comments2012 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2012 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2013 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1357027200.0\n",
      "endTime: 1388563199.0\n",
      "SELECT count(*) as 2013_Comments_Count from global_temp.Comments2013 where (created_utc>=1357027200.0 and created_utc<=1388563199.0 )\n",
      "+-------------------+\n",
      "|2013_Comments_Count|\n",
      "+-------------------+\n",
      "|           40195667|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2013 where subreddit='relationships' and (created_utc>=1357027200.0 and created_utc<=1388563199.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|        98820|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> import time\n",
    ">>> import datetime\n",
    ">>> dt = datetime.datetime.strptime('2013-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2013-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "\n",
    "sqlString=\"SELECT count(*) as 2013_Comments_Count from global_temp.Comments2013 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2013 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2014 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1388563200.0\n",
      "endTime: 1420099199.0\n",
      "SELECT count(*) as 2014_Comments_Count from global_temp.Comments2014 where (created_utc>=1388563200.0 and created_utc<=1420099199.0 )\n",
      "+-------------------+\n",
      "|2014_Comments_Count|\n",
      "+-------------------+\n",
      "|           53153633|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2014 where subreddit='relationships' and (created_utc>=1388563200.0 and created_utc<=1420099199.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|       179063|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> import time\n",
    ">>> import datetime\n",
    ">>> dt = datetime.datetime.strptime('2014-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2014-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "\n",
    "sqlString=\"SELECT count(*) as 2014_Comments_Count from global_temp.Comments2014 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2014 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2015 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1420099200.0\n",
      "endTime: 1451635199.0\n",
      "SELECT count(*) as 2015_Comments_Count from global_temp.Comments2015 where (created_utc>=1420099200.0 and created_utc<=1451635199.0 )\n",
      "+-------------------+\n",
      "|2015_Comments_Count|\n",
      "+-------------------+\n",
      "|           66731795|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2016 where subreddit='relationships' and (created_utc>=1420099200.0 and created_utc<=1451635199.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|          262|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> import time\n",
    ">>> import datetime\n",
    ">>> dt = datetime.datetime.strptime('2015-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2015-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "\n",
    "sqlString=\"SELECT count(*) as 2015_Comments_Count from global_temp.Comments2015 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2016 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2016 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1451635200.0\n",
      "endTime: 1483257599.0\n",
      "SELECT count(*) as 2016_Comments_Count from global_temp.Comments2016 where (created_utc>=1451635200.0 and created_utc<=1483257599.0 )\n",
      "+-------------------+\n",
      "|2016_Comments_Count|\n",
      "+-------------------+\n",
      "|           79936287|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Topic from global_temp.Comments2016 where subreddit='relationships' and (created_utc>=1451635200.0 and created_utc<=1483257599.0 )\n",
      "+------+\n",
      "| Topic|\n",
      "+------+\n",
      "|396043|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> import time\n",
    ">>> import datetime\n",
    ">>> dt = datetime.datetime.strptime('2016-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2016-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "\n",
    "sqlString=\"SELECT count(*) as 2016_Comments_Count from global_temp.Comments2016 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2016 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate %10 of 2017 Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startTime: 1483257600.0\n",
      "endTime: 1514793599.0\n",
      "SELECT count(*) as 2017_Comments_Count from global_temp.Comments2017 where (created_utc>=1483257600.0 and created_utc<=1514793599.0 )\n",
      "+-------------------+\n",
      "|2017_Comments_Count|\n",
      "+-------------------+\n",
      "|           22851079|\n",
      "+-------------------+\n",
      "\n",
      "SELECT count(*) as Relationships from global_temp.Comments2017 where subreddit='relationships' and (created_utc>=1483257600.0 and created_utc<=1514793599.0 )\n",
      "+-------------+\n",
      "|Relationships|\n",
      "+-------------+\n",
      "|        87045|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> import time\n",
    ">>> import datetime\n",
    ">>> dt = datetime.datetime.strptime('2017-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "startTime=time.mktime(dt.timetuple())\n",
    "print(\"startTime:\",startTime)\n",
    ">>> dt = datetime.datetime.strptime('2017-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "endTime=time.mktime(dt.timetuple())\n",
    "print(\"endTime:\",endTime)\n",
    "\n",
    "sqlString=\"SELECT count(*) as 2017_Comments_Count from global_temp.Comments2017 where (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n",
    "\n",
    "\n",
    "sqlString=\"SELECT count(*) as Relationships from global_temp.Comments2017 where subreddit='relationships' and (created_utc>=%s and created_utc<=%s )\";\n",
    "sqlString= sqlString % (startTime, endTime)\n",
    "print(sqlString)\n",
    "sqlDF=spark.sql(sqlString)\n",
    "\n",
    "commentCount = sqlDF.show(df.count());\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
